"""
Sakura War Room Audit: Chaos Engineering
=========================================
Proves system reliability under failure conditions.

Tests:
- Tool execution with 30% random failures
- Retry logic effectiveness
- Failover chain (Groq -> Gemini)

Output: audit_artifacts/reliability_report.txt
"""
import time
import random
import os
import sys

from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent / "backend"))

ARTIFACTS_DIR = os.path.join(os.path.dirname(__file__), "audit_artifacts")
os.makedirs(ARTIFACTS_DIR, exist_ok=True)


class ChaosInjector:
    """Wraps a tool to inject random failures."""
    
    def __init__(self, original_func, failure_rate=0.3, failure_types=None):
        self.original = original_func
        self.failure_rate = failure_rate
        self.failure_types = failure_types or [
            ("timeout", TimeoutError("Simulated API Timeout")),
            ("connection", ConnectionError("Simulated Connection Refused")),
            ("rate_limit", Exception("429 Rate Limited - Too Many Requests")),
        ]
        self.call_count = 0
        self.failure_count = 0
        
    def __call__(self, *args, **kwargs):
        self.call_count += 1
        
        if random.random() < self.failure_rate:
            self.failure_count += 1
            failure_type, error = random.choice(self.failure_types)
            raise error
        
        return self.original(*args, **kwargs)


def audit_tool_reliability():
    """
    Test tool execution reliability with injected failures.
    
    Uses mock tools to avoid actual API calls.
    """
    print("ðŸ’¥ Starting Chaos Engineering Audit...")
    
    # Mock tools that simulate real behavior
    def mock_spotify(args):
        time.sleep(0.01)  # Simulate network latency
        return "âœ… Playing: Neon Blade by Moonlight"
    
    def mock_weather(args):
        time.sleep(0.01)
        return "Weather: 22Â°C, Partly Cloudy"
    
    def mock_email(args):
        time.sleep(0.01)
        return "3 new emails in inbox"
    
    # Inject chaos
    tools = {
        "spotify_control": ChaosInjector(mock_spotify, failure_rate=0.30),
        "get_weather": ChaosInjector(mock_weather, failure_rate=0.20),
        "gmail_read_email": ChaosInjector(mock_email, failure_rate=0.15),
    }
    
    results = {}
    
    for tool_name, tool in tools.items():
        print(f"\n  Testing {tool_name} (failure_rate={tool.failure_rate*100:.0f}%)...")
        
        attempts = 100
        successes = 0
        retries_needed = 0
        
        for i in range(attempts):
            max_retries = 3
            success = False
            
            for retry in range(max_retries):
                try:
                    result = tool({})
                    successes += 1
                    success = True
                    if retry > 0:
                        retries_needed += 1
                    break
                except Exception as e:
                    if retry < max_retries - 1:
                        time.sleep(0.01)  # Backoff
                    continue
        
        survival_rate = (successes / attempts) * 100
        results[tool_name] = {
            "attempts": attempts,
            "successes": successes,
            "survival_rate": survival_rate,
            "injected_failures": tool.failure_count,
            "retries_helped": retries_needed,
        }
        
        print(f"    Survival Rate: {survival_rate:.1f}%")
        print(f"    Failures Injected: {tool.failure_count}")
    
    return results


def audit_llm_failover():
    """
    Test LLM failover chain (Primary -> Backup).
    """
    print("\nðŸ”„ Starting LLM Failover Audit...")
    
    results = {
        "failover_configured": False,
        "backup_available": False,
        "failover_logic_exists": False,
    }
    
    try:
        from sakura_assistant.core.models.wrapper import ReliableLLM
        from sakura_assistant.core.infrastructure.container import get_container
        import inspect
        
        # Check if failover logic exists in code
        source = inspect.getsource(ReliableLLM.invoke)
        results["failover_logic_exists"] = "backup" in source.lower() and "except" in source
        
        # Check container configuration
        container = get_container()
        results["backup_available"] = container.has_backup
        results["failover_configured"] = container.has_groq and container.has_backup
        
        print(f"  Failover Logic in Code: {results['failover_logic_exists']}")
        print(f"  Backup LLM Available: {results['backup_available']}")
        print(f"  Full Failover Configured: {results['failover_configured']}")
        
    except Exception as e:
        print(f"  âš ï¸ Failover audit failed: {e}")
    
    return results


def audit_executor_recovery():
    """
    Test executor's ability to recover from tool failures.
    
    Specifically tests the FALLBACK_MAP in executor.py
    """
    print("\nðŸ› ï¸ Starting Executor Recovery Audit...")
    
    results = {
        "fallback_map_exists": False,
        "fallback_chains": [],
    }
    
    try:
        from sakura_assistant.core.execution.executor import ToolExecutor, ExecutionPolicy
        
        if hasattr(ExecutionPolicy, 'FALLBACK_MAP'):
            results["fallback_map_exists"] = True
            results["fallback_chains"] = [
                f"{k} -> {v}" for k, v in ExecutionPolicy.FALLBACK_MAP.items()
            ]
            print(f"  Fallback chains found:")
            for chain in results["fallback_chains"]:
                print(f"    {chain}")
        else:
            print("  âš ï¸ No FALLBACK_MAP found in executor")
            
    except Exception as e:
        print(f"  âš ï¸ Recovery audit failed: {e}")
    
    return results


def generate_chaos_report(tool_results, failover_results, executor_results):
    """Generate the evidence report."""
    
    report_path = os.path.join(ARTIFACTS_DIR, "reliability_report.txt")
    
    with open(report_path, "w") as f:
        f.write("=" * 60 + "\n")
        f.write("SAKURA WAR ROOM: CHAOS ENGINEERING AUDIT\n")
        f.write("=" * 60 + "\n\n")
        
        f.write("METHODOLOGY:\n")
        f.write("- Injected random failures (15-30% rate)\n")
        f.write("- Measured survival rate with retry logic (3 attempts)\n")
        f.write("- Verified failover configuration\n\n")
        
        f.write("-" * 40 + "\n")
        f.write("TOOL RELIABILITY RESULTS:\n")
        f.write("-" * 40 + "\n")
        
        for tool_name, data in tool_results.items():
            f.write(f"\n{tool_name}:\n")
            f.write(f"  Attempts: {data['attempts']}\n")
            f.write(f"  Successes: {data['successes']}\n")
            f.write(f"  Survival Rate: {data['survival_rate']:.1f}%\n")
            f.write(f"  Failures Injected: {data['injected_failures']}\n")
        
        f.write("\n" + "-" * 40 + "\n")
        f.write("FAILOVER CHAIN STATUS:\n")
        f.write("-" * 40 + "\n")
        f.write(f"  Failover Logic in Code: {failover_results.get('failover_logic_exists', False)}\n")
        f.write(f"  Backup LLM Available: {failover_results.get('backup_available', False)}\n")
        f.write(f"  Full Chain Configured: {failover_results.get('failover_configured', False)}\n")
        
        f.write("\n" + "-" * 40 + "\n")
        f.write("EXECUTOR RECOVERY CHAINS:\n")
        f.write("-" * 40 + "\n")
        for chain in executor_results.get("fallback_chains", []):
            f.write(f"  {chain}\n")
        
        f.write("\n" + "=" * 60 + "\n")
        
        # Calculate overall score
        avg_survival = sum(d["survival_rate"] for d in tool_results.values()) / len(tool_results)
        grade = "A" if avg_survival >= 95 else "B" if avg_survival >= 85 else "C" if avg_survival >= 70 else "F"
        
        f.write(f"OVERALL RELIABILITY GRADE: {grade}\n")
        f.write(f"Average Survival Rate: {avg_survival:.1f}% (with 3 retries)\n")
        f.write(f"Target: >95% survival under 30% failure injection\n")
        f.write("=" * 60 + "\n")
    
    print(f"\nâœ… Report saved to {report_path}")
    return report_path


if __name__ == "__main__":
    print("=" * 60)
    print("SAKURA WAR ROOM: CHAOS ENGINEERING AUDIT")
    print("=" * 60)
    
    tool_results = audit_tool_reliability()
    failover_results = audit_llm_failover()
    executor_results = audit_executor_recovery()
    
    generate_chaos_report(tool_results, failover_results, executor_results)
    
    print("\n" + "=" * 60)
    print("CHAOS AUDIT COMPLETE - Check audit_artifacts/ for evidence")
    print("=" * 60)
