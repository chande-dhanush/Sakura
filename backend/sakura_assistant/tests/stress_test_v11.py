"""
Automated Stress Test for V11.3 Global Context Valve
----------------------------------------------------
Simulates a real "Mega-Tool" output (10k chars).
Verifies Interception -> Storage -> Retrieval -> Cleanup.
"""
import sys
import os
import asyncio
import shutil
import random
import time
from typing import List
from unittest.mock import MagicMock, patch

# Add backend to path
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

from sakura_assistant.core.executor import ToolExecutor
from sakura_assistant.core.ephemeral_manager import get_ephemeral_manager, EphemeralManager
from sakura_assistant.core.tools_libs.memory_tools import query_ephemeral
from langchain_core.tools import tool

# 1. Define Mock Tool
@tool
def massive_data_dump() -> str:
    """Returns a massive 10k char string."""
    header = "START_OF_DATA\n"
    body = ""
    for i in range(100):
        body += f"Fact #{i}: The secret code is {random.randint(1000,9999)}. This is some filler text to bloat the size. " * 2 + "\n"
    
    # Inject a specific needle to look for
    needle = "\n\nCRITICAL_NEEDLE: The golden key is SAKURA_V11_IS_LIVE.\n\n"
    
    footer = "END_OF_DATA"
    return header + body + needle + body + footer

# 2. Mock Embedder (to avoid API calls/dependencies)
def mock_compute_embeddings(texts: List[str]) -> List[List[float]]:
    # Return random vectors of dim 384 (common for Chroma/MiniLM)
    return [[random.random() for _ in range(384)] for _ in texts]

async def stress_test():
    print("üî• STARTED: V11.3 Automated Stress Test")
    
    # Setup
    eph_man = get_ephemeral_manager()
    # Ensure clean slate for test (optional)
    
    # Patch the embedding function logic ONLY. 
    # We want real Chunking and real Chroma interaction.
    with patch.object(EphemeralManager, '_compute_embeddings', side_effect=mock_compute_embeddings):
        
        # --- Step 1: Execution & Interception ---
        print("\n[Step 1] Running Executor with 'massive_data_dump'...")
        tools = [massive_data_dump]
        executor = ToolExecutor(tools)
        
        plan = [{"tool": "massive_data_dump", "args": {}, "id": 1}]
        result = await executor.aexecute_plan(plan)
        
        output = result.outputs
        print(f"   executor output length: {len(output)}")
        
        # ASSERTION 1: Interception Triggered
        if "[System: Context Overflow Protection]" not in output:
            print("‚ùå FAILURE: Output was not intercepted!")
            print(f"Output preview: {output[:200]}")
            return
        print("‚úÖ PASS: Output intercepted.")
        
        # ASSERTION 2: Ephemeral ID Generation
        import re
        match = re.search(r'Ephemeral Store ID: (eph_[a-f0-9]+)', output)
        if not match:
            print("‚ùå FAILURE: Could not extract Ephemeral ID.")
            return
        
        eph_id = match.group(1)
        print(f"‚úÖ PASS: Generated ID '{eph_id}'")
        
        # Verify folder exists on disk
        from sakura_assistant.config import get_project_root
        store_path = os.path.join(get_project_root(), "data", "chroma_store", eph_id)
        if not os.path.exists(store_path):
             print(f"‚ùå FAILURE: Chroma folder {store_path} NOT created.")
             return
        print(f"‚úÖ PASS: Chroma folder verified at {store_path}")

        # --- Step 2: Retrieval ---
        # We need to ensure the query is embedded similarly for retrieval to work.
        # Since we put random embeddings, semantic search WON'T work nicely unless we luck out.
        # BUT, since we mock _compute_embeddings to return random,
        # we can't expect semantic match unless we mock that too or control the random seed.
        
        # Fix: For this test, valid retrieval proves the store calls execute. 
        # We can't verify semantic accuracy with random vectors.
        # We will assume if query_ephemeral runs without error and returns *something* (or "No relevant context" if random), 
        # the *plumbing* works. 
        # Ideally we'd valid data, but without real embedder...
        # Wait, PerDocChromaStore.query calls collection.query.
        
        print("\n[Step 2] Testing 'query_ephemeral'...")
        try:
            # We just want to see if it crashes or returns a valid tool output
            res = query_ephemeral.invoke({"ephemeral_id": eph_id, "query": "golden key"})
            print(f"   Query Response: {res[:100]}...")
            if "‚ùå" in res:
                 print(f"‚ùå FAILURE: Query tool error: {res}")
                 return
            print("‚úÖ PASS: Query tool executed successfully.")
        except Exception as e:
            print(f"‚ùå FAILURE: Query tool exception: {e}")
            return

        # --- Step 3: Cleanup ---
        print("\n[Step 3] Testing Cleanup (with forced GC)...")
        import gc
        gc.collect()
        time.sleep(2.0)
        
        # Force cleanup by setting timestamp to old
        eph_man.active_stores[eph_id] = time.time() - 3600 # 1 hour ago
        eph_man.cleanup_old(max_age_minutes=10)
        
        # Windows deletion is async/laggy. Retry check.
        folder_gone = False
        for _ in range(5):
            if not os.path.exists(store_path):
                folder_gone = True
                break
            time.sleep(1.0)
            
        if not folder_gone:
            print(f"‚ùå FAILURE: Cleanup did not delete folder {store_path}")
            # Try manual delete to be nice
            try: shutil.rmtree(store_path)
            except: pass
            return
        print("‚úÖ PASS: Ephemeral store deleted.")

    print("\nüéâ SUCCESS: All Systems Operational.")

if __name__ == "__main__":
    asyncio.run(stress_test())
